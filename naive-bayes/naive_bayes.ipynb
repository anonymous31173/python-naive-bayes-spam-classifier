{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/usr/local/lib/python3.5/site-packages/lxml/etree.cpython-35m-darwin.so, 2): Library not loaded: libxml2.2.dylib\n  Referenced from: /usr/local/lib/python3.5/site-packages/lxml/etree.cpython-35m-darwin.so\n  Reason: Incompatible library version: etree.cpython-35m-darwin.so requires version 12.0.0 or later, but libxml2.2.dylib provides version 10.0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7bb5523cf2b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr/local/lib/python3.5/site-packages'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/lxml/html/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMutableSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_setmixin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSetMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/usr/local/lib/python3.5/site-packages/lxml/etree.cpython-35m-darwin.so, 2): Library not loaded: libxml2.2.dylib\n  Referenced from: /usr/local/lib/python3.5/site-packages/lxml/etree.cpython-35m-darwin.so\n  Reason: Incompatible library version: etree.cpython-35m-darwin.so requires version 12.0.0 or later, but libxml2.2.dylib provides version 10.0.0"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from decimal import Decimal\n",
    "import nltk\n",
    "import re\n",
    "import email.parser\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.5/site-packages')\n",
    "import lxml.html\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def extract_body(filename):\n",
    "    fp = open(filename)\n",
    "    msg = email.message_from_file(fp)\n",
    "    payload = msg.get_payload()\n",
    "    if type(payload) == type(list()):\n",
    "        payload = payload[0]\n",
    "    plain_text_body_content = lxml.html.document_fromstring(str(payload)).text_content()\n",
    "    return plain_text_body_content\n",
    "\n",
    "class NaiveBayes(object):\n",
    "    def __init__(self, categories):\n",
    "        self.words = defaultdict(dict)\n",
    "        self.categories = self._create_categories(categories)\n",
    "        self.training_examples = 0\n",
    "        self.unique_words = set()\n",
    "\n",
    "    def _create_categories(self, categories):\n",
    "        categories = {category: {'total': 0, 'word_count': 0}\n",
    "                      for category in categories}\n",
    "        return categories\n",
    "\n",
    "    def train(self, category, text):\n",
    "        text = self._tokenize_text(text)  # TODO: stem words\n",
    "\n",
    "        self._increment_unique_word_count(text)  # Laplace Smoothing\n",
    "        self._increment_word_frequency(category, text)\n",
    "        self._increment_category_count(category)\n",
    "        self._increment_category_word_count(category, len(text))\n",
    "\n",
    "        self.training_examples += 1\n",
    "\n",
    "    def _tokenize_text(self, text):\n",
    "        text = re.findall(r\"[\\w']+\", text)\n",
    "        words = []\n",
    "        for word in text:\n",
    "            if word and word not in nltk.corpus.stopwords.words('english'):\n",
    "                words.append(word)\n",
    "        return words\n",
    "\n",
    "    def _increment_word_frequency(self, category, words):\n",
    "        for word in words:\n",
    "            if self.words[word].get(category):\n",
    "                self.words[word][category] += 1\n",
    "            else:\n",
    "                self.words[word][category] = 1\n",
    "\n",
    "    def _increment_unique_word_count(self, text):\n",
    "        self.unique_words = set(list(self.unique_words) + text)\n",
    "\n",
    "    def _increment_category_count(self, category):\n",
    "        self.categories[category]['total'] += 1\n",
    "\n",
    "    def _increment_category_word_count(self, category, number):\n",
    "        if self.categories[category].get('word_count'):\n",
    "            self.categories[category]['word_count'] += number\n",
    "        else:\n",
    "            self.categories[category]['word_count'] = number\n",
    "\n",
    "    def classify(self, text):\n",
    "        text = self._tokenize_text(text)\n",
    "\n",
    "        probabilities = {}\n",
    "        for cat, cat_data in self.categories.iteritems():\n",
    "            category_prob = self._get_category_probability(cat_data['total'])\n",
    "            predictors_likelihood = self._get_predictors_probability(cat, text)\n",
    "            probabilities[cat] = category_prob * predictors_likelihood\n",
    "\n",
    "        return 1 if probabilities[1] > probabilities[0] else 0\n",
    "\n",
    "    def _get_category_probability(self, count):\n",
    "        # Can make use of logarithm in lieu of Python's decimal object to avoid\n",
    "        # Floating point underflow\n",
    "        # e.g. return log(class_prior_prob)\n",
    "        return Decimal(float(count)) / Decimal(self.training_examples + len(self.categories.keys()))\n",
    "\n",
    "    def _get_predictors_probability(self, category, text):\n",
    "        word_count = self.categories[category]['word_count'] + len(self.unique_words)\n",
    "        likelihood = 1\n",
    "        for word in text:\n",
    "            if not self.words.get(word) or not self.words[word].get(category):\n",
    "                smoothed_freq = 1  # Laplace smoothing\n",
    "            else:\n",
    "                smoothed_freq = 1 + self.words[word][category]\n",
    "            likelihood *= Decimal(float(smoothed_freq)) / Decimal(word_count)\n",
    "            # floating point underflow!! EEE!\n",
    "            # http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\n",
    "            # likelihood *= Decimal(float(self.words[word][category])) / Decimal(word_count)\n",
    "            # print category, log(predictor_likelihood)\n",
    "        return likelihood\n",
    "\n",
    "class SpamHamDetector(object):\n",
    "    def __init__(self, categories, path):\n",
    "        self.naive_bayes = NaiveBayes(categories)\n",
    "        self.path = path\n",
    "        self.classified_examples = dict()\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        with open('{0}/labels.csv'.format(self.path), 'r') as labels_csv:\n",
    "            reader = csv.DictReader(labels_csv)\n",
    "            for row in reader:\n",
    "                label = (row['Prediction'])\n",
    "                filename = '%s/TR/TRAIN_%s.eml' % (path, row['Id'])\n",
    "                try:\n",
    "                    body = extract_body(filename)\n",
    "                    self.naive_bayes.train(int(label), body)\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.info(\"Error training email %s: %s\", row['Id'], e.message)\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        all_ids = list(range(1, 2501))\n",
    "        random.shuffle(all_ids)\n",
    "        training_ids, labeling_ids = all_ids[:2250], all_ids[2250:]\n",
    "\n",
    "        with open('{0}/labels.csv'.format(self.path), 'r') as labels_csv:\n",
    "            reader = csv.DictReader(labels_csv)\n",
    "            for row in reader:\n",
    "                label = (row['Prediction'])\n",
    "                filename = '%s/TR/TRAIN_%s.eml' % (path, row['Id'])\n",
    "                if int(row['Id']) in training_ids:\n",
    "                    try:\n",
    "                        body = extract_body(filename)\n",
    "                        self.naive_bayes.train(int(label), body)\n",
    "                    except Exception as e:\n",
    "                        logger.info(\"Error training email %s: %s\", row['Id'], e.message)\n",
    "\n",
    "        correct, incorrect = 0, 0\n",
    "        with open('%s/labels.csv' % self.path, 'r') as labels_csv:\n",
    "            reader = csv.DictReader(labels_csv)\n",
    "            for row in reader:\n",
    "                label = (row['Prediction'])\n",
    "                filename = '%s/TR/TRAIN_%s.eml' % (path, row['Id'])\n",
    "                if int(row['Id']) in labeling_ids:\n",
    "                    try:\n",
    "                        test_body = extract_body(filename)\n",
    "                        result = self.naive_bayes.classify(test_body)\n",
    "                        if result == int(label):\n",
    "                            correct += 1\n",
    "                        else:\n",
    "                            incorrect += 1\n",
    "                    except Exception as e:\n",
    "                        logger.info(\"Error classifying email %s: %s\", row['Id'], e.message)\n",
    "        return self._calculate_results(correct, incorrect)\n",
    "\n",
    "    def classify(self, size):\n",
    "        counter = 1\n",
    "        test = self.path + '/TT/TEST_%s.eml'\n",
    "\n",
    "        while counter < size+1:\n",
    "            try:\n",
    "                test_body = extract_body(test % counter)\n",
    "                self.classified_examples[str(counter)] = str(self.naive_bayes.classify(test_body))\n",
    "            except Exception as e:\n",
    "                logger.info(\"Error classifying email %s: %s\", counter, e.message)\n",
    "            counter += 1\n",
    "\n",
    "        self._store_results()\n",
    "\n",
    "    def display_results(self):\n",
    "        spam = sum(1 for category in self.classified_examples.values() if category == '0')\n",
    "        ham = sum(1 for category in self.classified_examples.values() if category == '1')\n",
    "        return \"Spam Emails: %s\\nHam Emails: %s\\nSpam Percent: %s\\nHam Percent: %s\" \\\n",
    "               % (spam, ham, (float(spam) / len(self.classified_examples)),\n",
    "                  (float(ham) / len(self.classified_examples)))\n",
    "\n",
    "    def _calculate_results(self, correct, incorrect):\n",
    "        return \"correct %s, incorrect %s, performance measurement %s\" % (correct,\n",
    "                                                                         incorrect,\n",
    "                                                                         (float(correct) / (correct + incorrect)))\n",
    "\n",
    "    def _store_results(self):\n",
    "        with open('%s/results.csv' % self.path, 'w+') as resultscsv:\n",
    "            writer = csv.DictWriter(resultscsv, fieldnames=['id','Prediction'])\n",
    "            writer.writeheader()\n",
    "            for example_num, category in self.classified_examples.items():\n",
    "                writer.writerow({'id': example_num, 'Prediction': category})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"starting!\")\n",
    "path = os.path.dirname(__file__)\n",
    "detector = SpamHamDetector([0, 1], path)\n",
    "print(detector.train_and_evaluate())\n",
    "detector.train()\n",
    "print(\"done training!\")\n",
    "detector.classify(1827)\n",
    "print(\"done classifying!\")\n",
    "print(detector.display_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
